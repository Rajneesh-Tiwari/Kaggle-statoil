{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit,KFold\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2 # Used to manipulated the images \n",
    "np.random.seed(1337) # The seed I used - pick your own or comment out for a random seed. A constant seed allows for better comparisons though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"F:/Kaggle/Statoil/inputs/\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(input_path+\"train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(input_path+\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(sz, sz)\n",
    "        band_2 = np.array(row['band_2']).reshape(sz, sz)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 75\n",
    "X_train = get_scaled_imgs(train)\n",
    "X_test = get_scaled_imgs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of train: {} and test: {}\" .format(X_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "def gen_flow_for_test(X1, X2,y=None):\n",
    "    genX12 = gen.flow(X1,y, batch_size=batch_size,seed=55)\n",
    "    genX22 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X21i = genX12.next()\n",
    "            X22i = genX22.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X21i[0], X22i[1]]\n",
    "            \n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.01)\n",
    "    return [es, msave,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model Architecture (Kaggle can't access the weights file)\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def inceptionv3(img_dim=img_dim):\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    input_tensor = Input(shape=img_dim)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=img_dim)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    output = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[input_tensor, input_2], output=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = inceptionv3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and predict\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf,X_test_angle=X_test_angle):\n",
    "        \n",
    "    train_scores = []; valid_scores = []\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x[train_index]; x_valid = x[test_index]\n",
    "        y_train = y[train_index]; y_valid = y[test_index]\n",
    "\n",
    "        #Angle\n",
    "        X_angle_train = X_angle[train_index]\n",
    "        X_angle_valid = X_angle[test_index]\n",
    "        X_test_angle = X_test_angle\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                # Rotate 90\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                # flip vertically\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                # Rotate 180\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                # flip horizontally\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                # Rotate 90 counter-clockwise\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                # Rotate 180 and flip horizontally\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    y_batch = y_train[start:end]\n",
    "                    tr_angle = X_angle_train[start:end]\n",
    "                    for img in x_train[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        new_img = augment(new_img, np.random.randint(6))\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield [x_batch,tr_angle], y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    y_batch = y_valid[start:end]\n",
    "                    valid_angle = X_angle_valid[start:end]\n",
    "                    for img in x_valid[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield [x_batch ,valid_angle], y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), n_fold):\n",
    "                    x_batch = []\n",
    "                    end = min(start + n_fold, len(test))\n",
    "                    X_test_angle_test = X_test_angle[start:end]\n",
    "                    for img in test[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        new_img = augment(new_img, np.random.randint(6))  ### TTA step\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield [x_batch,X_test_angle_test]\n",
    "                    \n",
    "        callbacks = [EarlyStopping('val_loss', patience=10, mode=\"min\"),\n",
    "                    ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.01),\n",
    "                    ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / n_fold\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "\n",
    "        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n",
    "\n",
    "        \n",
    "        print('----------------------------------------')\n",
    "        print('Running train evaluation on fold {}'.format(i))\n",
    "        train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n",
    "        print('Running validation evaluation on fold {}'.format(i))\n",
    "        valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n",
    "        print('----------------------------------------')   \n",
    "        \n",
    "        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n",
    "                                                                            train_score[1], i))\n",
    "        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n",
    "                                                                            valid_score[1], i))\n",
    "        print('----------------------------------------')\n",
    "\n",
    "        train_scores.append(train_score[1])\n",
    "        valid_scores.append(valid_score[1])\n",
    "        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n",
    "              (np.mean(train_scores), np.mean(valid_scores), i))\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        print('Running test predictions with fold {}'.format(i))        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "    return preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_fold = 5\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "prediction_all_folds = train_model(model, batch_size, epochs, img_size, X_train, \n",
    "                                target_train, X_test, n_fold, kf,X_test_angle=X_test_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission\n",
    "import datetime as dt\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=prediction_all_folds\n",
    "submission.to_csv('F:/Kaggle/Statoil/submit/sub5cv_inceptionv3_tta_slight'+dt.datetime.today().strftime(\"%d%m%Y%H%M\")+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
